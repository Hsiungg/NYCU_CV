{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/train_Cellpose-SAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb90LCrotIx4"
   },
   "source": [
    "## Cellpose-SAM: superhuman generalization for cellular segmentation\n",
    "\n",
    "Marius Pachitariu, Michael Rariden, Carsen Stringer\n",
    "\n",
    "[paper](https://www.biorxiv.org/content/10.1101/2025.04.28.651001v1) | [code](https://github.com/MouseLand/cellpose)\n",
    "\n",
    "This notebook shows how to process your own 2D or 3D images, saved on Google Drive.\n",
    "\n",
    "This notebook is adapted from the notebook by Pradeep Rajasekhar, inspired by the [ZeroCostDL4Mic notebook series](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_iAN7cAthma"
   },
   "source": [
    "### Install Cellpose-SAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-05-16T19:37:53.231394Z",
     "iopub.status.busy": "2025-05-16T19:37:53.231200Z",
     "iopub.status.idle": "2025-05-16T19:39:29.132277Z",
     "shell.execute_reply": "2025-05-16T19:39:29.131359Z",
     "shell.execute_reply.started": "2025-05-16T19:37:53.231377Z"
    },
    "id": "hG3LSmJmLylT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/mouseland/cellpose.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnKdFgZTqmE9"
   },
   "source": [
    "Check GPU and instantiate model - will download weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-05-16T19:39:56.143873Z",
     "iopub.status.busy": "2025-05-16T19:39:56.143196Z",
     "iopub.status.idle": "2025-05-16T19:40:26.158395Z",
     "shell.execute_reply": "2025-05-16T19:40:26.157644Z",
     "shell.execute_reply.started": "2025-05-16T19:39:56.143829Z"
    },
    "id": "5ydQ-fggSiUm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cellpose import models, core, io, plot\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "io.logger_setup() # run this to get printing of progress\n",
    "\n",
    "#Check if colab notebook instance has GPU access\n",
    "if core.use_gpu()==False:\n",
    "  raise ImportError(\"No GPU access, change your runtime\")\n",
    "\n",
    "# models.CellposeModel(pretrained_model='/full/path/to/model')\n",
    "model = models.CellposeModel(gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plEha5EaqmE9"
   },
   "source": [
    "Input directory with your images (if you have them, otherwise use sample images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-05-16T14:00:42.218713Z",
     "iopub.status.busy": "2025-05-16T14:00:42.217881Z",
     "iopub.status.idle": "2025-05-16T14:00:42.254926Z",
     "shell.execute_reply": "2025-05-16T14:00:42.253991Z",
     "shell.execute_reply.started": "2025-05-16T14:00:42.218686Z"
    },
    "id": "-lZP6alpUAfY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # *** change to your google drive folder path ***\n",
    "# train_dir = \"/content/gdrive/MyDrive/PATH-TO-FILES/\"\n",
    "# if not Path(train_dir).exists():\n",
    "#   raise FileNotFoundError(\"directory does not exist\")\n",
    "\n",
    "# test_dir = None # optionally you can specify a directory with test files\n",
    "\n",
    "# # *** change to your mask extension ***\n",
    "# masks_ext = \"_seg.npy\"\n",
    "# # ^ assumes images from Cellpose GUI, if labels are tiffs, then \"_masks.tif\"\n",
    "\n",
    "# # list all files\n",
    "# files = [f for f in Path(train_dir).glob(\"*\") if \"_masks\" not in f.name and \"_flows\" not in f.name and \"_seg\" not in f.name]\n",
    "\n",
    "# if(len(files)==0):\n",
    "#   raise FileNotFoundError(\"no files found, did you specify the correct folder and extension?\")\n",
    "# else:\n",
    "#   print(f\"{len(files)} files in folder:\")\n",
    "\n",
    "# for f in files:\n",
    "#   print(f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JnV_E_OqmE9"
   },
   "source": [
    "### Sample images (optional)\n",
    "\n",
    "You can use our sample images instead of mounting your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T14:24:35.157356Z",
     "iopub.status.busy": "2025-05-16T14:24:35.156367Z",
     "iopub.status.idle": "2025-05-16T14:24:50.911074Z",
     "shell.execute_reply": "2025-05-16T14:24:50.910188Z",
     "shell.execute_reply.started": "2025-05-16T14:24:35.157299Z"
    },
    "id": "sG96J_V8qmE-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from cellpose import utils\n",
    "from pathlib import Path\n",
    "\n",
    "# url = \"https://drive.google.com/uc?id=1HXpLczf7TPCdI1yZY5KV3EkdWzRrgvhQ\"\n",
    "# utils.download_url_to_file(url, \"human_in_the_loop.zip\")\n",
    "\n",
    "# !unzip human_in_the_loop\n",
    "\n",
    "# train_dir = \"human_in_the_loop/train/\"\n",
    "# test_dir = \"human_in_the_loop/test/\"\n",
    "\n",
    "# masks_ext = \"_seg.npy\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJFJG-mkqmE-"
   },
   "source": [
    "## Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T19:40:36.331738Z",
     "iopub.status.busy": "2025-05-16T19:40:36.331240Z",
     "iopub.status.idle": "2025-05-16T19:40:52.067024Z",
     "shell.execute_reply": "2025-05-16T19:40:52.066232Z",
     "shell.execute_reply.started": "2025-05-16T19:40:36.331715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 設定路徑\n",
    "image_dir = '/kaggle/input/sartorius-cell-instance-segmentation/train'  # 存放 xxx.png 的資料夾\n",
    "mask_dict = np.load('/kaggle/input/all-instance-masks-npy/all_instance_masks.npy', allow_pickle=True).item()\n",
    "\n",
    "image_arrays = []\n",
    "mask_arrays = []\n",
    "\n",
    "# 確保按照檔名排序（可選）\n",
    "image_filenames = sorted(os.listdir(image_dir))\n",
    "\n",
    "for filename in image_filenames:\n",
    "    if not filename.endswith('.png'):\n",
    "        continue\n",
    "\n",
    "    image_id = os.path.splitext(filename)[0]  # 取得 'xxx' 作為 key\n",
    "\n",
    "    # 讀圖並轉為 numpy array（轉成 RGB）\n",
    "    img_path = os.path.join(image_dir, filename)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # 找到對應的 mask\n",
    "    if image_id not in mask_dict:\n",
    "        print(f\"⚠️ 找不到 {image_id} 的 mask，略過。\")\n",
    "        continue\n",
    "\n",
    "    mask = mask_dict[image_id]  # mask 是 np.uint16\n",
    "\n",
    "    image_arrays.append(img_np)\n",
    "    mask_arrays.append(mask)\n",
    "\n",
    "    if len(image_arrays) % 50 == 0:\n",
    "        print(f\"已處理 {len(image_arrays)} 張圖像\")\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "    image_arrays, mask_arrays, test_size=0.2, random_state=63\n",
    ")\n",
    "\n",
    "print(len(train_images), len(val_images), len(train_masks), len(val_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T19:41:13.844444Z",
     "iopub.status.busy": "2025-05-16T19:41:13.843967Z",
     "iopub.status.idle": "2025-05-16T21:02:19.973432Z",
     "shell.execute_reply": "2025-05-16T21:02:19.972811Z",
     "shell.execute_reply.started": "2025-05-16T19:41:13.844422Z"
    },
    "id": "r0umDFliqmE-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from cellpose import train\n",
    "\n",
    "\n",
    "model_name = \"new_model\"\n",
    "\n",
    "# default training params\n",
    "n_epochs = 20\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.1\n",
    "batch_size = 2\n",
    "\n",
    "# get files\n",
    "# output = io.load_train_test_data(train_dir, test_dir, mask_filter=masks_ext)\n",
    "# train_data, train_labels, _, test_data, test_labels, _ = output\n",
    "\n",
    "\n",
    "# 轉為 numpy array 儲存\n",
    "# image_array_np = np.array(image_arrays)\n",
    "# mask_array_np = np.array(mask_arrays)\n",
    "\n",
    "\n",
    "# (not passing test data into function to speed up training)\n",
    "\n",
    "new_model_path, train_losses, test_losses = train.train_seg(model.net,\n",
    "                                                            train_data=train_images,\n",
    "                                                            train_labels=train_masks,\n",
    "                                                            test_data =val_images,\n",
    "                                                            test_labels = val_masks,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            n_epochs=n_epochs,\n",
    "                                                            min_train_masks=0,\n",
    "                                                            learning_rate=learning_rate,\n",
    "                                                            weight_decay=weight_decay,\n",
    "                                                            nimg_per_epoch=max(2, len(train_images)), # can change this\n",
    "                                                            model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gj0EdXtcqmE-"
   },
   "source": [
    "## Evaluate on test data (optional)\n",
    "\n",
    "If you have test data, check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2Gv4KnSqmE-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from cellpose import metrics\n",
    "\n",
    "model = models.CellposeModel(gpu=True,\n",
    "                             pretrained_model=new_model_path)\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OddRFdtEqmE-"
   },
   "source": [
    "plot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T14:33:22.483266Z",
     "iopub.status.busy": "2025-05-16T14:33:22.482615Z",
     "iopub.status.idle": "2025-05-16T14:33:23.434640Z",
     "shell.execute_reply": "2025-05-16T14:33:23.433557Z",
     "shell.execute_reply.started": "2025-05-16T14:33:22.483242Z"
    },
    "id": "9MUrvy5JqmE-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "for k,im in enumerate(test_data):\n",
    "    img = im.copy()\n",
    "    plt.subplot(3,len(test_data), k+1)\n",
    "    img = np.vstack((img, np.zeros_like(img)[:1]))\n",
    "    img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('image')\n",
    "\n",
    "    plt.subplot(3,len(test_data), len(test_data) + k+1)\n",
    "    plt.imshow(masks[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('predicted labels')\n",
    "\n",
    "    plt.subplot(3,len(test_data), 2*len(test_data) + k+1)\n",
    "    plt.imshow(test_labels[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('true labels')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2750748,
     "isSourceIdPinned": false,
     "sourceId": 30201,
     "sourceType": "competition"
    },
    {
     "datasetId": 1660631,
     "sourceId": 2724590,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7438870,
     "sourceId": 11839904,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
